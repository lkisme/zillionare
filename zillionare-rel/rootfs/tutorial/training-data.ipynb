{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import pandas as pd\n",
    "r = redis.Redis(host='redis', port=6379, db=1, decode_responses=True)   \n",
    "lst = []\n",
    "#\"code\":code, \"exchange\":jys, \"jq_code\":code,\"name\":sec[\"display_name\"],\"pinyin\":sec[\"name\"],\"start\":sec[\"start_date\"],\"end\":sec[\"end_date\"],\"type\":sec[\"type\"]\n",
    "for index in range(r.llen('securities')):\n",
    "    info = r.lindex(\"securities\", index)\n",
    "    #000001.XSHE,平安银行,PAYH,1991-04-03,2200-01-01,stock\n",
    "    data = info.split(\",\")\n",
    "    jqCode = data[0]\n",
    "    codes = jqCode.split(\".\")\n",
    "    code = codes[0]\n",
    "    jys = \"sh\"\n",
    "    if 'XSHE'==codes[1]:\n",
    "        jys = \"sz\"\n",
    "    lst.append([code, jys, jqCode, data[1], data[2], data[3],data[4], data[5]])\n",
    "pdd = pd.DataFrame(lst,columns = [\"code\", \"exchange\", \"jq_code\",\"name\",\"pinyin\",\"start\",\"end\",\"type\"])\n",
    "    \n",
    "print(r.lindex(\"securities\", 0))\n",
    "print(r.llen('securities'))  # 取出键 name 对应的值\n",
    "#print(pdd)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b271ee8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to read form JQ\n",
      "{'total': 500000, 'spare': 475551}\n"
     ]
    }
   ],
   "source": [
    "# 获取地域。这里要使用finance中的查询\n",
    "import os\n",
    "import jqdatasdk as jq\n",
    "from jqdatasdk import finance\n",
    "from jqdatasdk import query\n",
    "from sqlalchemy import create_engine\n",
    "print(\"Start to read form JQ\")\n",
    "account = os.environ['JQ_ACCOUNT']\n",
    "password = os.environ['JQ_PASSWORD']\n",
    "jq.auth(account, password)\n",
    "print(jq.get_query_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48419be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.joinquant.com/help/api/help#JQData:股票行情数据\n",
    "#获取贵州茅台按天为周期以\"2018-12-05\"为基础往前5个交易日的数据\n",
    "#df = jq.get_bars('600519.XSHG', 5, unit='1d',fields=['date','open','high','low','close'],include_now=False,end_dt='2018-12-05')\n",
    "\n",
    "# https://www.joinquant.com/help/api/help#JQData:通用行情接口\n",
    "#获取平安银行按1分钟为周期以“2015-01-30 14:00:00”为基础前4个时间单位的数据\n",
    "#df = jq.get_price('000001.XSHE', end_date='2022-02-21 14:00:00',count=100, frequency='minute', fields=['open','close','low','high','volume','money','factor','high_limit','low_limit','avg','pre_close','paused','open_interest'])\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa30206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec_num: 15154\n",
      "size: 1\n",
      "size: 1\n",
      "size: 2\n",
      "size: 2\n",
      "size: 2\n",
      "size: 3\n",
      "size: 3\n",
      "size: 4\n",
      "size: 4\n",
      "size: 5\n",
      "size: 5\n",
      "size: 6\n",
      "size: 6\n",
      "size: 7\n",
      "size: 7\n",
      "size: 8\n",
      "size: 8\n",
      "size: 9\n",
      "size: 9\n",
      "size: 10\n",
      "size: 10\n",
      "size: 11\n",
      "size: 11\n",
      "size: 11\n",
      "size: 12\n",
      "size: 12\n",
      "size: 13\n",
      "size: 13\n",
      "size: 14\n",
      "size: 14\n",
      "size: 14\n",
      "size: 14\n",
      "size: 15\n",
      "size: 15\n",
      "size: 16\n",
      "size: 16\n",
      "size: 17\n",
      "size: 17\n",
      "size: 17\n",
      "size: 17\n",
      "size: 18\n",
      "size: 18\n",
      "size: 19\n",
      "size: 19\n",
      "size: 20\n",
      "size: 20\n",
      "size: 21\n",
      "size: 21\n",
      "size: 22\n",
      "size: 22\n",
      "size: 23\n",
      "size: 23\n",
      "size: 24\n",
      "size: 24\n",
      "size: 25\n",
      "size: 25\n",
      "size: 26\n",
      "size: 26\n",
      "size: 26\n",
      "size: 26\n",
      "size: 27\n",
      "size: 27\n",
      "size: 28\n",
      "size: 28\n",
      "size: 29\n",
      "size: 29\n",
      "size: 30\n",
      "size: 30\n",
      "size: 31\n",
      "size: 31\n",
      "size: 32\n",
      "size: 32\n",
      "size: 33\n",
      "size: 33\n",
      "size: 33\n",
      "size: 34\n",
      "size: 34\n",
      "size: 34\n",
      "size: 34\n",
      "size: 34\n",
      "size: 35\n",
      "size: 35\n",
      "size: 36\n",
      "size: 36\n",
      "size: 36\n",
      "size: 37\n",
      "size: 37\n",
      "size: 38\n",
      "size: 38\n",
      "size: 39\n",
      "size: 39\n",
      "size: 39\n",
      "size: 39\n",
      "size: 39\n",
      "size: 39\n",
      "size: 40\n",
      "size: 40\n",
      "size: 41\n",
      "size: 41\n",
      "size: 41\n",
      "size: 42\n",
      "size: 42\n",
      "size: 43\n",
      "size: 43\n",
      "size: 44\n",
      "size: 44\n",
      "size: 45\n",
      "size: 45\n",
      "size: 46\n",
      "size: 46\n",
      "size: 47\n",
      "size: 47\n",
      "size: 47\n",
      "size: 48\n",
      "size: 48\n",
      "size: 49\n",
      "size: 49\n",
      "size: 49\n",
      "size: 50\n",
      "size: 50\n",
      "size: 51\n",
      "size: 51\n",
      "size: 52\n",
      "size: 52\n",
      "size: 52\n",
      "size: 52\n",
      "size: 52\n",
      "size: 52\n",
      "size: 52\n",
      "size: 52\n",
      "size: 52\n",
      "size: 53\n",
      "size: 53\n",
      "size: 53\n",
      "size: 54\n",
      "size: 55\n",
      "size: 56\n",
      "size: 56\n",
      "size: 56\n",
      "size: 56\n",
      "size: 56\n",
      "size: 56\n",
      "size: 56\n",
      "size: 57\n",
      "size: 57\n",
      "size: 57\n",
      "size: 57\n",
      "size: 58\n",
      "size: 58\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 59\n",
      "size: 60\n",
      "size: 60\n",
      "size: 61\n",
      "size: 61\n",
      "size: 61\n",
      "size: 62\n",
      "size: 62\n",
      "size: 63\n",
      "size: 63\n",
      "size: 64\n",
      "size: 65\n",
      "size: 66\n",
      "size: 66\n",
      "size: 67\n",
      "size: 67\n",
      "size: 67\n",
      "size: 67\n",
      "size: 67\n",
      "size: 68\n",
      "size: 68\n",
      "size: 68\n",
      "size: 68\n",
      "size: 69\n",
      "size: 70\n",
      "size: 71\n",
      "size: 72\n",
      "size: 73\n",
      "size: 74\n",
      "size: 75\n",
      "size: 76\n",
      "size: 76\n",
      "size: 77\n",
      "size: 78\n",
      "size: 79\n",
      "size: 80\n",
      "size: 81\n",
      "size: 82\n",
      "size: 83\n",
      "size: 84\n",
      "size: 85\n",
      "size: 85\n",
      "size: 86\n",
      "size: 87\n",
      "size: 88\n",
      "size: 89\n",
      "size: 90\n",
      "size: 91\n",
      "size: 92\n",
      "size: 93\n",
      "size: 94\n",
      "size: 95\n",
      "size: 96\n",
      "size: 97\n",
      "size: 98\n",
      "size: 98\n",
      "size: 99\n",
      "size: 100\n",
      "size: 101\n",
      "size: 102\n",
      "size: 103\n",
      "size: 104\n",
      "size: 105\n",
      "size: 105\n",
      "size: 106\n",
      "size: 107\n",
      "size: 107\n",
      "size: 108\n",
      "size: 109\n",
      "size: 110\n",
      "size: 111\n",
      "size: 112\n",
      "size: 113\n",
      "size: 113\n",
      "size: 114\n",
      "size: 115\n",
      "size: 116\n",
      "size: 117\n",
      "size: 117\n",
      "size: 118\n",
      "size: 119\n",
      "size: 120\n",
      "size: 121\n",
      "size: 122\n",
      "size: 123\n",
      "size: 124\n",
      "size: 124\n",
      "size: 125\n",
      "size: 126\n",
      "size: 127\n",
      "size: 128\n",
      "size: 129\n",
      "size: 130\n",
      "size: 131\n",
      "size: 132\n",
      "size: 133\n",
      "size: 134\n",
      "size: 135\n",
      "size: 136\n",
      "size: 136\n",
      "size: 137\n",
      "size: 138\n",
      "size: 139\n",
      "size: 140\n",
      "size: 141\n",
      "size: 142\n",
      "size: 143\n",
      "size: 144\n",
      "size: 145\n",
      "size: 146\n",
      "size: 147\n",
      "size: 147\n",
      "size: 148\n",
      "size: 149\n",
      "size: 150\n",
      "size: 151\n",
      "size: 152\n",
      "size: 153\n",
      "size: 153\n",
      "size: 154\n",
      "size: 155\n",
      "size: 156\n",
      "size: 157\n",
      "size: 158\n",
      "size: 158\n",
      "size: 159\n",
      "size: 160\n",
      "size: 160\n",
      "size: 161\n",
      "size: 161\n",
      "size: 162\n",
      "size: 163\n",
      "size: 164\n",
      "size: 165\n",
      "size: 166\n",
      "size: 167\n",
      "size: 168\n",
      "size: 168\n",
      "size: 169\n",
      "size: 170\n",
      "size: 171\n",
      "size: 172\n",
      "size: 173\n",
      "size: 174\n",
      "size: 175\n",
      "size: 175\n",
      "size: 176\n",
      "size: 177\n",
      "size: 178\n",
      "size: 179\n",
      "size: 180\n",
      "size: 181\n",
      "size: 182\n",
      "size: 182\n",
      "size: 183\n",
      "size: 183\n",
      "size: 184\n",
      "size: 185\n",
      "size: 186\n",
      "size: 186\n",
      "size: 187\n",
      "size: 188\n",
      "size: 189\n",
      "size: 190\n",
      "size: 191\n",
      "size: 192\n",
      "size: 193\n",
      "size: 194\n",
      "size: 195\n",
      "size: 196\n",
      "size: 197\n",
      "size: 198\n",
      "size: 199\n",
      "error:  000001.XSHE\n",
      "error:  000002.XSHE\n",
      "error:  000004.XSHE\n",
      "error:  000005.XSHE\n",
      "error:  000006.XSHE\n",
      "error:  000007.XSHE\n",
      "error:  000008.XSHE\n",
      "error:  000009.XSHE\n",
      "error:  000010.XSHE\n",
      "error:  000011.XSHE\n",
      "error:  000012.XSHE\n",
      "error:  000014.XSHE\n",
      "error:  000016.XSHE\n",
      "error:  000017.XSHE\n",
      "error:  000019.XSHE\n",
      "error:  000020.XSHE\n",
      "error:  000021.XSHE\n",
      "error:  000023.XSHE\n",
      "error:  000025.XSHE\n",
      "error:  000026.XSHE\n",
      "error:  000027.XSHE\n",
      "error:  000028.XSHE\n",
      "error:  000029.XSHE\n",
      "error:  000030.XSHE\n",
      "error:  000031.XSHE\n",
      "error:  000032.XSHE\n",
      "error:  000034.XSHE\n",
      "error:  000035.XSHE\n",
      "error:  000036.XSHE\n",
      "error:  000037.XSHE\n",
      "error:  000038.XSHE\n",
      "error:  000039.XSHE\n",
      "error:  000040.XSHE\n",
      "error:  000042.XSHE\n",
      "error:  000045.XSHE\n",
      "error:  000046.XSHE\n",
      "error:  000048.XSHE\n",
      "error:  000049.XSHE\n",
      "error:  000050.XSHE\n",
      "error:  000055.XSHE\n",
      "error:  000056.XSHE\n",
      "error:  000058.XSHE\n",
      "error:  000059.XSHE\n",
      "error:  000060.XSHE\n",
      "error:  000061.XSHE\n",
      "error:  000062.XSHE\n",
      "error:  000063.XSHE\n",
      "error:  000065.XSHE\n",
      "error:  000066.XSHE\n",
      "error:  000068.XSHE\n",
      "error:  000069.XSHE\n",
      "error:  000070.XSHE\n",
      "error:  000078.XSHE\n",
      "error:  000088.XSHE\n",
      "error:  000089.XSHE\n",
      "error:  000090.XSHE\n",
      "error:  000096.XSHE\n",
      "error:  000099.XSHE\n",
      "error:  000100.XSHE\n",
      "error:  000150.XSHE\n",
      "error:  000151.XSHE\n",
      "error:  000153.XSHE\n",
      "error:  000155.XSHE\n",
      "error:  000156.XSHE\n",
      "error:  000157.XSHE\n",
      "error:  000158.XSHE\n",
      "error:  000159.XSHE\n",
      "error:  000166.XSHE\n",
      "error:  000301.XSHE\n",
      "error:  000333.XSHE\n",
      "error:  000338.XSHE\n",
      "error:  000400.XSHE\n"
     ]
    }
   ],
   "source": [
    "import redis    \n",
    "from Ashare.Ashare import *\n",
    "from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED, FIRST_COMPLETED\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "#https://blog.csdn.net/rubysxl/article/details/103947739\n",
    "from sqlalchemy import create_engine\n",
    "#这里MySQL必须与zillionare在同一个网卡上\n",
    "engine = create_engine(\"mysql+pymysql://root:123456@mysql:3306/stock\")\n",
    "\n",
    "def get_result(future):\n",
    "    print(\"---1 task done---\")\n",
    "\n",
    "def get_bar_from_jq_and_push_db(codes,count, unit,end_date):\n",
    "    bars = jq.get_bars(codes, count, unit=unit,fields=[\"date\", \"open\", \"close\", \"high\", \"low\", \"volume\", \"money\",\"factor\"],df=False,include_now=False,end_dt=end_date)\n",
    "    #处理数据\n",
    "    print(\"Try to getbars：\",count, \", got bars: \", len(bars))\n",
    "    for code in codes:\n",
    "        bar = bars[code]\n",
    "    #     df = dfs.loc(code)\n",
    "#             print(df)\n",
    "        df = pd.DataFrame(bar)\n",
    "    #     df.insert(data.shape[1], 'd', 0)\n",
    "        df['code'] = code\n",
    "        df['unit'] = unit\n",
    "#             print(df)\n",
    "        df.to_sql(name=\"t_bars\",con=engine,if_exists='append',index=False,index_label=False)\n",
    "    \n",
    "def get_bar_from_ashare_and_push_db(codes,count, unit,end_date=''):\n",
    "    for code in codes:\n",
    "        try:\n",
    "            bars=get_price(code = code,frequency=unit,count = count, end_date = end_date)      #默认获取今天往前5天的日线实时行情\n",
    "            #处理数据\n",
    "    #         print(\"Got bars: \", len(bars))\n",
    "            bars['code'] = code\n",
    "            bars['unit'] = unit\n",
    "            bars['date'] = bars.index\n",
    "    #         print(bars)\n",
    "    #         bars.to_sql(name=\"t_bars\",con=engine,if_exists='append',index=False,index_label=False)\n",
    "            bars.to_sql(name=\"t_bars\",con=engine,if_exists='append',index=False,index_label=False)\n",
    "        except:\n",
    "            print(\"error: \",code)\n",
    "    \n",
    "r = redis.Redis(host='redis', port=6379, db=1, decode_responses=True)   \n",
    "batch_size = 200\n",
    "size = 0\n",
    "codes = []\n",
    "sec_num = r.llen('securities')\n",
    "print('sec_num:', sec_num)\n",
    "#units = ['1m', '5m', '15m', '30m', '60m', '120m', '1d', '1w', '1M']\n",
    "# 创建一个包含20条线程的线程池\n",
    "pool = ThreadPoolExecutor(max_workers=20)\n",
    "futures =[]\n",
    "#\"code\":code, \"exchange\":jys, \"jq_code\":code,\"name\":sec[\"display_name\"],\"pinyin\":sec[\"name\"],\"start\":sec[\"start_date\"],\"end\":sec[\"end_date\"],\"type\":sec[\"type\"]\n",
    "for index in range(sec_num):\n",
    "    info = r.lindex(\"securities\", index)\n",
    "    #000001.XSHE,平安银行,PAYH,1991-04-03,2200-01-01,stock\n",
    "    data = info.split(\",\")\n",
    "    jqCode = data[0]\n",
    "    type = data[5]\n",
    "    end = pd.to_datetime(data[4])\n",
    "    now = pd.Timestamp.now()\n",
    "#     if end > now:\n",
    "#         print(\"end > now\")\n",
    "        \n",
    "#     else:\n",
    "#         print(\"end < now\")\n",
    "        \n",
    "        \n",
    "    stock_legal = \"stock\" == type and end > now and (not jqCode.startswith('68')) and (not jqCode.startswith('3'))\n",
    "    if stock_legal:\n",
    "        codes.append(jqCode)\n",
    "        size = size +1\n",
    "    \n",
    "#    print(\"size:\", size)\n",
    "    if (stock_legal and size == batch_size) or index+1 == sec_num:\n",
    "#         get_bar_from_jq_and_push_db(codes, 1000, '1d','2022-02-22')\n",
    "        get_bar_from_ashare_and_push_db(codes, count = 600,unit = '60m',end_date='2023-02-22')\n",
    "        future = pool.submit(get_bar_from_ashare_and_push_db, codes, count = 100,unit = '1d',end_date='2023-02-22')\n",
    "        futures.append(future)\n",
    "        future.add_done_callback(get_result)\n",
    "        codes = []\n",
    "        size = 0\n",
    "        #插入数据\n",
    "    print(\"size:\", size)\n",
    "print(\"for loop end\")\n",
    "wait(futures,return_when=ALL_COMPLETED)        \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8392acd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to read form JQ\n",
      "auth success \n",
      "{'total': 500000, 'spare': 0}\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "您当天的查询条数超过了每日最大查询限制：50万条；付费可增加流量权限，详情请咨询管理员：\nhttps://www.joinquant.com/help/api/doc?name=logon&id=9831",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m codes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m000613.XSHE\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m000615.XSHE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#非DataFrame格式\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m dfs \u001b[38;5;241m=\u001b[39m \u001b[43mjq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhigh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvolume\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmoney\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfactor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43minclude_now\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mend_dt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2022-02-21\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#print(dfs)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m code \u001b[38;5;129;01min\u001b[39;00m codes:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/jqdatasdk/utils.py:308\u001b[0m, in \u001b[0;36massert_auth.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run jqdatasdk.auth first\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/jqdatasdk/api.py:631\u001b[0m, in \u001b[0;36mget_bars\u001b[0;34m(security, count, unit, fields, include_now, end_dt, fq_ref_date, df)\u001b[0m\n\u001b[1;32m    629\u001b[0m end_dt \u001b[38;5;241m=\u001b[39m to_date_str(end_dt)\n\u001b[1;32m    630\u001b[0m fq_ref_date \u001b[38;5;241m=\u001b[39m to_date_str(fq_ref_date)\n\u001b[0;32m--> 631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mJQDataClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bars\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/jqdatasdk/client.py:347\u001b[0m, in \u001b[0;36mJQDataClient.__getattr__.<locals>.<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, method):\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/jqdatasdk/client.py:331\u001b[0m, in \u001b[0;36mJQDataClient.__call__\u001b[0;34m(self, method, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_attempt_count):\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m socket_error \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/jqdatasdk/client.py:271\u001b[0m, in \u001b[0;36mJQDataClient.query\u001b[0;34m(self, method, params)\u001b[0m\n\u001b[1;32m    269\u001b[0m         result \u001b[38;5;241m=\u001b[39m pc\u001b[38;5;241m.\u001b[39mload(buffer, encoding\u001b[38;5;241m=\u001b[39mpickle_encoding)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_error(response)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     buffer\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mException\u001b[0m: 您当天的查询条数超过了每日最大查询限制：50万条；付费可增加流量权限，详情请咨询管理员：\nhttps://www.joinquant.com/help/api/doc?name=logon&id=9831"
     ]
    }
   ],
   "source": [
    "# 获取地域。这里要使用finance中的查询\n",
    "import os\n",
    "import jqdatasdk as jq\n",
    "from jqdatasdk import finance\n",
    "from jqdatasdk import query\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Start to read form JQ\")\n",
    "account = os.environ['JQ_ACCOUNT']\n",
    "password = os.environ['JQ_PASSWORD']\n",
    "jq.auth(account, password)\n",
    "print(jq.get_query_count())\n",
    "\n",
    "codes = ['000613.XSHE','000615.XSHE']\n",
    "#非DataFrame格式\n",
    "dfs = jq.get_bars(codes, 5, unit='1d',fields=[\"date\", \"open\", \"close\", \"high\", \"low\", \"volume\", \"money\",\"factor\"],df=False,include_now=False,end_dt='2022-02-21')\n",
    "#print(dfs)\n",
    "for code in codes:\n",
    "    df = dfs[code]\n",
    "#     df = dfs.loc(code)\n",
    "    print(df)\n",
    "    dfdf = pd.DataFrame(df)\n",
    "#     df.insert(data.shape[1], 'd', 0)\n",
    "    dfdf['code'] = code\n",
    "#     print(dfdf)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfc10595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     date  open  close  high   low      volume        money  \\\n",
      "000613.XSHE 0  2022-02-17  3.93   3.87  3.93  3.86   1696400.0    6601399.0   \n",
      "            1  2022-02-18  3.86   3.93  3.95  3.85   1726600.0    6762443.0   \n",
      "000615.XSHE 0  2022-02-17  8.29   8.20  8.42  8.18  13954096.0  115645608.0   \n",
      "            1  2022-02-18  8.11   8.37  8.39  8.00  17585338.0  145159654.0   \n",
      "\n",
      "               factor  \n",
      "000613.XSHE 0   1.430  \n",
      "            1   1.430  \n",
      "000615.XSHE 0   9.466  \n",
      "            1   9.466  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'000613.XSHE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py:3080\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:101\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:4554\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:4562\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '000613.XSHE'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(dfs)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m code \u001b[38;5;129;01min\u001b[39;00m codes:\n\u001b[0;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdfs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     df = dfs.loc(code)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3024\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3024\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3026\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py:3082\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3081\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3082\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tolerance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     tolerance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_tolerance(tolerance, np\u001b[38;5;241m.\u001b[39masarray(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: '000613.XSHE'"
     ]
    }
   ],
   "source": [
    "#从jq拿数据\n",
    "codes = ['000338.XSHE','000615.XSHE']\n",
    "#DataFrame格式\n",
    "dfs = jq.get_bars(codes, 2, unit='1d',fields=[\"date\", \"open\", \"close\", \"high\", \"low\", \"volume\", \"money\",\"factor\"],include_now=False,end_dt='2022-02-21')\n",
    "print(dfs)\n",
    "for code in codes:\n",
    "    df = dfs[code]\n",
    "#     df = dfs.loc(code)\n",
    "    print(df)\n",
    "    dfdf = pd.DataFrame(df)\n",
    "#     df.insert(data.shape[1], 'd', 0)\n",
    "    dfdf['code'] = code\n",
    "    print(dfdf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d983ef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "0 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momicron\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtimeframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf\n\u001b[1;32m      4\u001b[0m end \u001b[38;5;241m=\u001b[39m arrow\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022-02-22\u001b[39m\u001b[38;5;124m'\u001b[39m, tzinfo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsia/Shanghai\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m240\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFrameType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMIN1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(start,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, end)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/omicron/core/timeframe.py:305\u001b[0m, in \u001b[0;36mTimeFrame.shift\u001b[0;34m(cls, moment, n, frame_type)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m frame_type \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    297\u001b[0m     FrameType\u001b[38;5;241m.\u001b[39mMIN1,\n\u001b[1;32m    298\u001b[0m     FrameType\u001b[38;5;241m.\u001b[39mMIN5,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m     FrameType\u001b[38;5;241m.\u001b[39mMIN60,\n\u001b[1;32m    302\u001b[0m ]:\n\u001b[1;32m    303\u001b[0m     tm \u001b[38;5;241m=\u001b[39m moment\u001b[38;5;241m.\u001b[39mhour \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m+\u001b[39m moment\u001b[38;5;241m.\u001b[39mminute\n\u001b[0;32m--> 305\u001b[0m     new_tick_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mticks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mframe_type\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m n\n\u001b[1;32m    306\u001b[0m     days \u001b[38;5;241m=\u001b[39m new_tick_pos \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mticks[frame_type])\n\u001b[1;32m    307\u001b[0m     min_part \u001b[38;5;241m=\u001b[39m new_tick_pos \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mticks[frame_type])\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in list"
     ]
    }
   ],
   "source": [
    "import arrow # arrow是一个时间处理库\n",
    "from omicron.core.types import FrameType\n",
    "from omicron.core.timeframe import tf\n",
    "end = arrow.get('2022-02-21 15:00:00', tzinfo='Asia/Shanghai')\n",
    "start = tf.shift(end, -240, FrameType.MIN1)\n",
    "print(start,\":\", end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8506dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got bars:  800\n",
      "                      open  close   high    low     volume\n",
      "                                                          \n",
      "2022-04-27 10:30:00  10.50  10.43  10.75  10.41  247381.18\n",
      "2022-04-27 11:30:00  10.43  10.51  10.55  10.36  129439.33\n",
      "2022-04-27 14:00:00  10.51  10.84  10.87  10.51  198287.01\n",
      "2022-04-27 15:00:00  10.84  10.87  10.88  10.74  139940.01\n",
      "2022-04-28 10:30:00  10.76  10.93  10.97  10.74  170162.94\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2023-02-21 15:00:00  12.93  12.98  12.98  12.86  131822.79\n",
      "2023-02-22 10:30:00  12.88  12.73  12.92  12.69  275763.00\n",
      "2023-02-22 11:30:00  12.72  12.80  12.85  12.72   80211.00\n",
      "2023-02-22 14:00:00  12.80  12.82  12.88  12.73   97532.00\n",
      "2023-02-22 15:00:00  12.82  12.83  12.90  12.80  111508.00\n",
      "\n",
      "[800 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from Ashare.Ashare import *\n",
    "\n",
    "codes = ['000338.XSHE','000615.XSHE']\n",
    "\n",
    "def get_bar_from_ashare_and_push_db(codes,count, unit,end_date=''):\n",
    "    for code in codes:\n",
    "        bars=get_price(code = code,frequency=unit,count = count, end_date = end_date)      #默认获取今天往前5天的日线实时行情\n",
    "        #处理数据\n",
    "        print(\"Got bars: \", len(bars))\n",
    "#         bars['code'] = code\n",
    "#         bars['unit'] = unit\n",
    "#         bars['date'] = bars.index\n",
    "        print(bars)\n",
    "#         df.to_sql(name=\"t_bars\",con=engine,if_exists='append',index=False,index_label=False)\n",
    "    \n",
    "get_bar_from_ashare_and_push_db(codes = ['000338.XSHE'],count = 800,unit = '60m',end_date='2022-02-22')\n",
    "# get_bar_from_ashare_and_push_db(codes, 100, '1d','2023-02-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d99e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
